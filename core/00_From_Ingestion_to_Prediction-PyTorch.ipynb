{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Prediction example:**  \n",
    "___\n",
    "In this example we will show how to:\n",
    "- Setup the required environment for accessing the ecosystem prediction server.\n",
    "- Upload data to ecosystem prediction server.\n",
    "- Load data into feature store and parse to frame.\n",
    "- Build and test a prediction model for prism scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up import path:**  \n",
    "___\n",
    "Add path of ecosystem notebook wrappers. It needs to point to the ecosystem notebook wrapper to allow access to the packages required for running the prediction server via python.\n",
    "- **notebook_path:** Path to notebook repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = \"/path of to ecosystem notebook repository\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "import sys\n",
    "sys.path.append(notebook_path)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Import required packages:**  \n",
    "___\n",
    "Import and load all packages required for the following usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "import pymongo\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy\n",
    "import operator\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from prediction import jwt_access\n",
    "from prediction import notebook_functions\n",
    "from prediction.apis import functions\n",
    "from prediction.apis import data_munging_engine\n",
    "from prediction.apis import worker_h2o\n",
    "from prediction.apis import prediction_engine\n",
    "from prediction.apis import worker_file_service\n",
    "\n",
    "%matplotlib inline\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Setup prediction server access:**  \n",
    "___\n",
    "Create access token for prediction server.\n",
    "- **url:** Url for the prediction server to access.\n",
    "- **username:** Username for prediction server.\n",
    "- **password:** Password for prediction server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"http://demo.ecosystem.ai:3001/api\"\n",
    "username = \"user@ecosystem.ai\"\n",
    "password = \"cd486be3-9955-4364-8ccc-a9ab3ffbc168\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "auth = jwt_access.Authenticate(url, username, password)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Upload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**List uploaded files:**  \n",
    "___\n",
    "List all files already uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "files = worker_file_service.get_files(auth, path=\"./\", user=username)\n",
    "files = files[\"item\"]\n",
    "for file in files:\n",
    "    file_name = file[\"name\"]\n",
    "    fn_parts = file_name.split(\".\")\n",
    "    if len(fn_parts) > 1 and fn_parts[-1] != \"log\":\n",
    "        print(file_name)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**List uploadable files:**  \n",
    "___\n",
    "List all files in path ready for upload to prediction server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "path = \"../example_data/\"\n",
    "upload_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "print(upload_files)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Upload file:**  \n",
    "___\n",
    "Select file to upload to prediction server.\n",
    "- **file_name:** file name of file to upload to prediction server. See list of available files for upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name = \"multi_personality_tiny.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "worker_file_service.upload_file(auth, path + file_name, \"/data/\")\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**List uploaded files:**  \n",
    "___\n",
    "List all files in path ready for upload to prediction server to compare with previous list to confirm that file was uploaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "files = worker_file_service.get_files(auth, path=\"./\", user=username)\n",
    "files = files[\"item\"]\n",
    "for file in files:\n",
    "    file_name = file[\"name\"]\n",
    "    fn_parts = file_name.split(\".\")\n",
    "    if len(fn_parts) > 1 and fn_parts[-1] != \"log\":\n",
    "        print(file_name)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Model:**\n",
    "___\n",
    "Set training parameters for model and train.\n",
    "- **predict_id:** Id for the prediction (for logging). \n",
    "- **description:** Description of model (for logging).\n",
    "- **model_id:** Id for the model (for logging).\n",
    "- **model_type:** Type of model to build (for logging). \n",
    "- **frame_name:** Name of frame used (for logging).\n",
    "- **frame_name_desc:** Description of frame used (for logging).\n",
    "- **model_purpose:** Purpose of model (for logging).\n",
    "- **version:** Model version (for logging).\n",
    "\n",
    "The following parameters are dependend on what is selected in the algo parameter.\n",
    "\n",
    "- **algo:** Algorithm to use to train model. (Availble algorithms: \"H20-AUTOML\", \"PYTORCH\")\n",
    "- **transformer:** Pytorch transformer to use. (Available transformers: \"bert-base-uncase\")\n",
    "- **model_name:** Output name of model being built.\n",
    "- **device:** Hardware on which to build model. (Available devices: \"cpu\")\n",
    "- **data_file_path:** Path to input data file.\n",
    "- **data_file_type:** Type of input data file. (Available types: \"csv\")\n",
    "- **model_path:** Path to output model.\n",
    "- **training_column:** Column in dataset containing training text.\n",
    "- **response_column:** Column in dataset containing predictor reponse.\n",
    "- **epochs:** Number of epochs for which to train the model.\n",
    "- **learning_rate:** (TODO)\n",
    "- **epsilon:** (TODO)\n",
    "- **seed:** Random seed with which to run training of model.\n",
    "- **model_checkpoint:** If set to True, will save model as a checkout of the base transformer, if false a whole model will be saved.\n",
    "- **train_test_split:** Percentage of data to use for validation.\n",
    "- **do_lower_case:** If True, for input text to lowercase.\n",
    "- **batch_size:** Number of rows in data to process concurrently.\n",
    "- **add_special_tokens:** If set to True, special tokens will be added to tokenized data.\n",
    "- **padding:** If input is less than max_length the fill rest of tokenized data with padding tokens.\n",
    "- **max_length:** Max length for tokenizers to allow.\n",
    "- **truncation:** If set to True, if input is more than max_length then data will be truncated to max_length. If set to False, if input is more than max_length model will not train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"1010\"\n",
    "model_id = featurestore_name + version\n",
    "model_purpose = \"Prediction of personality based on text data.\"\n",
    "description = \"Automated features store generated for \" + featurestore_name\n",
    "model_params = { \n",
    "        \"predict_id\": featurestore_name,\n",
    "        \"description\": description,\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": \"PYTORCH\",\n",
    "        \"frame_name\": hexframename,\n",
    "        \"frame_name_desc\": description,\n",
    "        \"model_purpose\": model_purpose,\n",
    "        \"version\": version,\n",
    "        \"model_parms\": {\n",
    "            \"algo\": \"PYTORCH\",\n",
    "            \"transformer\": \"bert-base-uncased\",\n",
    "            \"transformer_configs\": {\n",
    "                \"model_name\": \"personality\",\n",
    "                \"device\": \"cpu\",\n",
    "                \"data_file_path\": \"data/multi_personality_tiny.csv\",\n",
    "                \"data_file_type\": \"csv\",\n",
    "                \"model_path\": \"modeling/personality.model\",\n",
    "                \"training_column\": \"text\",\n",
    "                \"response_column\": \"response\",\n",
    "                \"epochs\": 1,\n",
    "                \"learning_rate\": 0.00001,\n",
    "                \"epsilon\": 1e-8,\n",
    "                \"seed\": 17,\n",
    "                \"model_checkpoint\": false,\n",
    "                \"train_test_split\": 0.15,\n",
    "                \"do_lower_case\": true,\n",
    "                \"batch_size\": 10,\n",
    "                \"add_special_tokens\": true,\n",
    "                \"padding\": true,\n",
    "                \"max_length\": 512,\n",
    "                \"truncation\": true\n",
    "      }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "worker_h2o.train_model(auth, model_id, \"pytorch\", json.dumps(model_params[\"model_parms\"]))\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**View Model:**\n",
    "___\n",
    "View autoML model to see which generated models are performing the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "model_data = worker_h2o.get_train_model(auth, model_id, \"AUTOML\")\n",
    "notebook_functions.RenderJSON(model_data)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sort_metric = model_data[\"leaderboard\"][\"sort_metric\"]\n",
    "model_names = []\n",
    "for model in model_data[\"leaderboard\"][\"models\"]:\n",
    "    model_names.append(model[\"name\"])\n",
    "\n",
    "model_metrics = model_data[\"leaderboard\"][\"sort_metrics\"]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"model_names\": model_names,\n",
    "        \"model_metrics\": model_metrics\n",
    "    }\n",
    ")\n",
    "df.sort_values(\"model_metrics\", inplace=True, ascending=False)\n",
    "ax = df.plot(y=\"model_metrics\", x=\"model_names\", kind=\"bar\", align=\"center\", alpha=0.5, legend=None)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_title(\"Performance of Models. Sorted Using Metric: {}\".format(sort_metric))\n",
    "ax.yaxis.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Save Model:**\n",
    "___\n",
    "Save model for prediction.\n",
    "- **model_id:** Id for the model to save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = df.iloc[0][\"model_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o_name = best_model\n",
    "zip_name = h2o_name + \".zip\"\n",
    "# worker_h2o.download_model_mojo(auth, h2o_name)\n",
    "high_level_mojo = worker_h2o.get_train_model(auth, h2o_name, \"single\")\n",
    "model_to_save = high_level_mojo[\"models\"][0]\n",
    "model_to_save[\"model_identity\"] = h2o_name\n",
    "model_to_save[\"userid\"] = \"user\"\n",
    "model_to_save[\"timestamp\"] = \"time_stamp\"\n",
    "prediction_engine.save_model(auth, model_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**View Model Stats:**\n",
    "___\n",
    "View stats of saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_engine.get_user_model(auth, h2o_name) \n",
    "stats = worker_h2o.get_model_stats(auth, h2o_name, \"ecosystem\", \"variable_importances\")\n",
    "notebook_functions.RenderJSON(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
