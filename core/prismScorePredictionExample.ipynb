{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the server\n",
    "import jwt_access\n",
    "\n",
    "url = \"url of server here\"\n",
    "username = \"your username\"\n",
    "password = \"your password\"\n",
    "\n",
    "auth = jwt_access.Authenticate(url, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path for accessing ecosystem python wrappers\n",
    "import sys\n",
    "sys.path.append(\"/path of ecosystem server python wrappers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pymongo\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "import pandas as p\n",
    "import json\n",
    "import numpy\n",
    "import operator\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from apis import functions as uf\n",
    "from apis import data_management_engine as d\n",
    "from apis import data_munging_engine as dm\n",
    "from apis import worker_h2o as hw\n",
    "from apis import prediction_engine as pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up mongo databse connection ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\n",
    "   \"mongodb://connection details\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client[\"database name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual feature store enrichment example ##\n",
    "\n",
    "#### Get a list of field names in the feature stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_pipeline = [\n",
    "    {\"$project\":{\"arrayofkeyvalue\":{\"$objectToArray\":\"$$ROOT\"}}},\n",
    "    {\"$unwind\":\"$arrayofkeyvalue\"},\n",
    "    {\"$group\":{\"_id\":None,\"allkeys\":{\"$addToSet\":\"$arrayofkeyvalue.k\"}}}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.featureStoreOfCategories.aggregate(fields_pipeline)\n",
    "doc = cursor.next()\n",
    "listOfFields = doc[\"allkeys\"]\n",
    "if \"_id\" in listOfFields: listOfFields.remove(\"_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of the year month week combos used in the feature store names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_months = [\"list of month indicators to add to base feature stores\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add one step lags to all of the feature stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(list_of_months)-1):\n",
    "    print(j)\n",
    "    current_fs = \"baseFeatureStore\"+list_of_months[j+1]\n",
    "    previous_fs = \"baseFeatureStore\"+list_of_months[j]\n",
    "    write_fs = \"baseFeatureStoreLags\"+list_of_months[j]\n",
    "    ratio_pipeline = [\n",
    "                        {\n",
    "                        \"$lookup\":{\n",
    "                                \"from\":previous_fs\n",
    "                                ,\"localField\":\"_id\"\n",
    "                                ,\"foreignField\":\"_id\"\n",
    "                                ,\"as\":\"subs\"\n",
    "                                }\n",
    "                        }\n",
    "                        ,{\"$unwind\":\"$subs\"}\n",
    "                        ,{\n",
    "                        \"$addFields\":{\n",
    "                                    }\n",
    "                        }\n",
    "                        ,{\"$unset\":\"subs\"}\n",
    "                        ,{\"$out\":write_fs}\n",
    "                    ]\n",
    "    \n",
    "    for i in listOfFields:\n",
    "        add_field = i+\"Ratio\"\n",
    "        add_field_appear = i+\"Appear\"\n",
    "        current_value = \"$\"+ i\n",
    "        previous_value = \"$subs.\" + i\n",
    "        ratio_pipeline[2][\"$addFields\"][add_field]={\"$switch\":{\"branches\":[\n",
    "                         {\"case\":{\"$and\":[{\"$ne\":[{\"$type\":current_value}, \"missing\"]},{\"$ne\":[{\"$type\":previous_value}, \"missing\"]}]}, \"then\":{\"$divide\":[current_value,previous_value]}}\n",
    "                        ,{\"case\":{\"$and\":[{\"$ne\":[{\"$type\":current_value}, \"missing\"]},{\"$eq\":[{\"$type\":previous_value}, \"missing\"]}]}, \"then\":0}\n",
    "                        ], \"default\":None}}\n",
    "        ratio_pipeline[2][\"$addFields\"][add_field_appear]={\"$cond\":[{\"$and\":[{\"$eq\":[{\"$type\":current_value}, \"missing\"]},{\"$ne\":[{\"$type\":previous_value}, \"missing\"]}]},1,0]}\n",
    "    \n",
    "    db[current_fs].aggregate(ratio_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add behaviour change indiciator showing number of categories appearing or disappearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(list_of_months)-1):\n",
    "    add_dict = {\"$addFields\":\n",
    "                       {\n",
    "                        \"appear\":{\"$add\":[]}\n",
    "                        ,\"disappear\":{\"$add\":[]}\n",
    "                       }\n",
    "           }\n",
    "    for i in listOfFields:\n",
    "        field_disappear = \"$\"+i+\"Ratio\"\n",
    "        field_appear = \"$\"+i+\"Appear\"\n",
    "        add_dict[\"$addFields\"][\"appear\"][\"$add\"].append({\"$cond\":[{\"$eq\":[field_appear,1]},1,0]})\n",
    "        add_dict[\"$addFields\"][\"disappear\"][\"$add\"].append({\"$cond\":[{\"$eq\":[field_disappear,0]},1,0]})\n",
    "\n",
    "    write_fs = \"fnbPrismFeatureStoreLags\"+list_of_months[j]\n",
    "    print(write_fs)\n",
    "    behav_change_pipeline = [\n",
    "        add_dict\n",
    "        ,{\"$out\":write_fs}\n",
    "    ]\n",
    "\n",
    "    db[write_fs].aggregate(behav_change_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an h2o model using the ecosystem.ai packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set column data types - this is approximate and should be checked\n",
    "fs = \"training feature store\"\n",
    "export_store = fs\n",
    "export_store_file = export_store+\".csv\"\n",
    "example_data = d.get_data(auth,\"fnb_stage1\", fs, \"{}\", 10, \"{}\", 0)\n",
    "example_data_frame = p.DataFrame(example_data)\n",
    "listOfColumnNames = list(example_data_frame.columns)\n",
    "export_projection = \"\"\n",
    "for i in listOfColumnNames:\n",
    "    export_projection = export_projection + i + \",\"\n",
    "\n",
    "export_projection = export_projection[:-1]\n",
    "d.export_documents(auth,export_store, \"csv\", \"fnb_stage1\", export_store, \"{}\", \"{}\", export_projection, 75000)\n",
    "parsed = hw.file_to_frame(auth,export_store_file, 1, \"comma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathvar = \"/Users/ecosystem/data/fnb_2020_05/\" + fs +\".csv\"\n",
    "hexframename = uf.save_userframe(example_data_frame, fs, pathvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model training parameters\n",
    "model_id = fs+modelIdInc\n",
    "model_purpose = \"Prediction of whether nonbehavioural prism model is correct\"\n",
    "model_params = { \n",
    "        \"predict_id\": fs,\n",
    "        \"description\": descrip,\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": \"AUTOML\",\n",
    "        \"frame_name\": hexframename,\n",
    "        \"frame_name_desc\": descrip,\n",
    "        \"model_purpose\": model_purpose,\n",
    "        \"version\": modelIdInc,\n",
    "        \"model_parms\": {\n",
    "              \"algo\": \"H2O-AUTOML\",\n",
    "              \"training_frame\": hexframename,\n",
    "              \"validation_frame\": hexframename,\n",
    "              \"max_models\": 10,\n",
    "              \"stopping_tolerance\": 0.005,\n",
    "              \"note_stop\": \"stopping_tolerance of 0.001 for 1m rows and 0.004 for 100k rows\",\n",
    "              \"max_runtime_secs\": 3600,\n",
    "              \"stopping_rounds\": 15,\n",
    "              \"stopping_metric\": \"AUTO\",\n",
    "              \"nfolds\": 4,\n",
    "              \"note_folds\": \"nfolds=0 will disable the stacked ensemble creation process\",\n",
    "              \"response_column\": \"prismResponse\",\n",
    "              \"ignored_columns\": [            \n",
    "                  \"prismResponse\",\n",
    "                  \"other columns in feature store you don\"t want to be included in the model\"\n",
    "              ],\n",
    "              \"hidden\": [\n",
    "                \"1\"\n",
    "              ],\n",
    "              \"exclude_algos\": [\n",
    "                \"GLM\",\n",
    "                \"StackedEnsemble\",\n",
    "                \"XGBoost\",\n",
    "                \"DeepLearning\",\n",
    "                \"GBM\",\n",
    "                \"Any algorithms that you don\"t want to be included in the automl run\"\n",
    "              ]\n",
    "            }\n",
    "    }\n",
    "#Start the model training\n",
    "hw.train_model(auth, model_id, \"automl\", json.dumps(model_params[\"model_parms\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "h2o_name = \"name of the best model\"\n",
    "correct_models_dict[j] = h2o_name\n",
    "zip_name = h2o_name + \".zip\"\n",
    "hw.download_model_mojo(auth,h2o_name)\n",
    "high_level_mojo=hw.get_train_model(auth, h2o_name, \"eric\")\n",
    "model_to_save = high_level_mojo[\"models\"][0]\n",
    "model_to_save[\"model_identity\"] = h2o_name\n",
    "model_to_save[\"userid\"] = \"jayvanzyl\"\n",
    "model_to_save[\"timestamp\"] = \"time_stamp\"\n",
    "pe.save_model(auth,model_to_save)\n",
    "\n",
    "#See some statistics from the saved model\n",
    "pe.get_user_model(auth,h2o_name)\n",
    "stats = hw.get_model_stats(auth,h2o_name,\"ecosystem\",\"variable_importances\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
