{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prism score prediction example:**  \n",
    "___\n",
    "In this example we will show how to:\n",
    "- Setup the required environment for accessing the ecosystem prediction server.\n",
    "- Setup access to the mongo database.\n",
    "- Enrich feature stores.\n",
    "- Build and test a prediction model for prism scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Setting up import path:**  \n",
    "___\n",
    "Add path of ecosystem notebook wrappers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set path for accessing ecosystem python wrappers\n",
    "import sys\n",
    "sys.path.append(\"/path of ecosystem server python wrappers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Setup prediction server access:**  \n",
    "___\n",
    "Create access token for prediction server.\n",
    "- **url:** Url for the prediction server to access.\n",
    "- **username:** Username for prediction server.\n",
    "- **password:** Password for prediction server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Successful.\n"
     ]
    }
   ],
   "source": [
    "#Access the server\n",
    "from prediction import jwt_access\n",
    "\n",
    "url = \"http://demo.ecosystem.ai:3001/api\"\n",
    "username = \"user@ecosystem.ai\"\n",
    "password = \"cd486be3-9955-4364-8ccc-a9ab3ffbc168\"\n",
    "\n",
    "auth = jwt_access.Authenticate(url, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Import required packages:**  \n",
    "___\n",
    "Import and load all packages required for the following usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load packages\n",
    "import pymongo\n",
    "from bson.son import SON\n",
    "import pprint\n",
    "import pandas as p\n",
    "import json\n",
    "import numpy\n",
    "import operator\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from prediction.apis import functions as uf\n",
    "from prediction.apis import data_management_engine as d\n",
    "from prediction.apis import data_munging_engine as dm\n",
    "from prediction.apis import worker_h2o as hw\n",
    "from prediction.apis import prediction_engine as pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Mongo Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Setting up mongo connection string:**  \n",
    "___\n",
    "Creat connection string to allow access to mongo database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(\n",
    "   \"mongodb://ecosystem_user:EcoEco321@demo.ecosystem.ai:54445/?authSource=admin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Connect to mongo database:**  \n",
    "___\n",
    "Connect to specified mongo database.\n",
    "- **database:** Name of database to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "database = \"notebook_algorithms\"\n",
    "db = client[database]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Show mongo collections:**  \n",
    "___\n",
    "Show all collections for the specifed mongo database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bank_transactions_MAR2019', 'lags_bank_transactions_JAN2019', 'bank', 'test_sample', 'bank_transactions_FEB2019', 'bank_transaction', 'lags_bank_transactions_FEB2019', 'bank_transactions_JAN2019', 'test_sample2']\n"
     ]
    }
   ],
   "source": [
    "collections = db.list_collection_names()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Feature Store Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**List fields:**  \n",
    "___\n",
    "List all fields in the specified collection.\n",
    "- **collection:** Name of the collection. (See list above for available collections.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['effReformatted', 'account_type', 'MCC', 'eff_date', 'customer', 'effYearMonth', 'trns_amt', 'intl_ind', 'trns_type']\n"
     ]
    }
   ],
   "source": [
    "collection = \"bank_transaction\"\n",
    "list_of_fields = uf.get_list_of_fields(db, collection)\n",
    "print(list_of_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**List of feature stores:**  \n",
    "___\n",
    "Create list of feature stores to enrich.\n",
    "- **list_of_fs:** Names of the collections to enrich. (See list above for available collections.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_of_fs = [\n",
    "    \"bank_transactions_FEB2019\",\n",
    "    \"bank_transactions_JAN2019\",\n",
    "    \"bank_transactions_MAR2019\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Add lag to feature stores:**  \n",
    "___\n",
    "Add a single step lag to all features stores listed in **list_of_fs**.\n",
    "- **lag_prefix:** Prefix to add to new feature stores created with added lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lag_prefix = \"lags_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# ---- Uneditible ----\n",
    "for j in range(len(list_of_fs)-1):\n",
    "    print(j)\n",
    "    current_fs = list_of_fs[j+1]\n",
    "    previous_fs = list_of_fs[j]\n",
    "    write_fs = lag_prefix + list_of_fs[j]\n",
    "    ratio_pipeline = [\n",
    "                        {\n",
    "                        \"$lookup\":{\n",
    "                                \"from\":previous_fs\n",
    "                                ,\"localField\":\"_id\"\n",
    "                                ,\"foreignField\":\"_id\"\n",
    "                                ,\"as\":\"subs\"\n",
    "                                }\n",
    "                        }\n",
    "                        ,{\"$unwind\":\"$subs\"}\n",
    "                        ,{\n",
    "                        \"$addFields\":{\n",
    "                                    }\n",
    "                        }\n",
    "                        ,{\"$unset\":\"subs\"}\n",
    "                        ,{\"$out\":write_fs}\n",
    "                    ]\n",
    "    \n",
    "    for i in list_of_fields:\n",
    "        add_field = i+\"Ratio\"\n",
    "        add_field_appear = i+\"Appear\"\n",
    "        current_value = \"$\"+ i\n",
    "        previous_value = \"$subs.\" + i\n",
    "        ratio_pipeline[2][\"$addFields\"][add_field]={\"$switch\":{\"branches\":[\n",
    "                         {\"case\":{\"$and\":[{\"$ne\":[{\"$type\":current_value}, \"missing\"]},{\"$ne\":[{\"$type\":previous_value}, \"missing\"]}]}, \"then\":{\"$divide\":[current_value,previous_value]}}\n",
    "                        ,{\"case\":{\"$and\":[{\"$ne\":[{\"$type\":current_value}, \"missing\"]},{\"$eq\":[{\"$type\":previous_value}, \"missing\"]}]}, \"then\":0}\n",
    "                        ], \"default\":None}}\n",
    "        ratio_pipeline[2][\"$addFields\"][add_field_appear]={\"$cond\":[{\"$and\":[{\"$eq\":[{\"$type\":current_value}, \"missing\"]},{\"$ne\":[{\"$type\":previous_value}, \"missing\"]}]},1,0]}\n",
    "    \n",
    "    db[current_fs].aggregate(ratio_pipeline)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Add behavior change indicator:**  \n",
    "___\n",
    "Add a behaviour change indicator showing the number of categories appearing or disappearing.\n",
    "- **prism_lag_prefix:** Prefix to add to new feature stores created with added behaviour change indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prism_lag_prefix = \"prism_lags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ---- Uneditible ----\n",
    "for j in range(len(list_of_fs)-1):\n",
    "    add_dict = {\"$addFields\":\n",
    "                       {\n",
    "                        \"appear\":{\"$add\":[]}\n",
    "                        ,\"disappear\":{\"$add\":[]}\n",
    "                       }\n",
    "           }\n",
    "    for i in list_of_fields:\n",
    "        field_disappear = \"$\"+i+\"Ratio\"\n",
    "        field_appear = \"$\"+i+\"Appear\"\n",
    "        add_dict[\"$addFields\"][\"appear\"][\"$add\"].append({\"$cond\":[{\"$eq\":[field_appear,1]},1,0]})\n",
    "        add_dict[\"$addFields\"][\"disappear\"][\"$add\"].append({\"$cond\":[{\"$eq\":[field_disappear,0]},1,0]})\n",
    "\n",
    "    write_fs = prism_lag_prefix + list_of_fs[j]\n",
    "    print(write_fs)\n",
    "    behav_change_pipeline = [\n",
    "        add_dict\n",
    "        ,{\"$out\":write_fs}\n",
    "    ]\n",
    "\n",
    "    db[write_fs].aggregate(behav_change_pipeline)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Export training data:**  \n",
    "___\n",
    "Find and export training data for prediction model and then read exported data into a dataframe.\n",
    "- **fs:** Name for training data feature store.\n",
    "- **db_name:** Name of database to access.\n",
    "- **record_count:** Number of records to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fs = \"prism_data\"\n",
    "db_name = \"notebook_algorithms\"\n",
    "record_count = 75000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get /getMongoDBFind?database=notebook_algorithms&collection=prism_data&field={}&limit=10&projections={}&skip=0&\n"
     ]
    }
   ],
   "source": [
    "# ---- Uneditible ----\n",
    "export_store = fs\n",
    "export_store_file = export_store + \".csv\"\n",
    "example_data = d.get_data(auth, db_name, fs, \"{}\", 10, \"{}\", 0)\n",
    "example_data_frame = p.DataFrame(example_data)\n",
    "listOfColumnNames = list(example_data_frame.columns)\n",
    "export_projection = \"\"\n",
    "for i in listOfColumnNames:\n",
    "    export_projection = export_projection + i + \",\"\n",
    "export_projection = export_projection[:-1]\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get /getMongoDBFind?database=notebook_algorithms&collection=prism_data&field={}&limit=10&projections={}&skip=0&\n",
      "get /exportMongoDocuments?file_name=prism_data&file_type=csv&database=notebook_algorithms&collection=prism_data&field={}&sort={}&projection=NO_ZFN_ACCT,Experiential,15427Spend,15712Spend,WedSpend,Introvert,5541Frequency,CUST_CREDIT_LIMIT,DiscretionaryFrequency,CIF_ADDR_VERIFY,CUST_TOT_DR_BAL,NO_POST_ADDR,15309Frequency,RGN_CDE,15314Spend,Enthusiastic,ExtrovertFrequency,MKT_POST,15309Spend,CashSpend,EssentialSpend,15749Frequency,KYC_IND,CUST_AGE,badIndicatorBrs,15466Frequency,GRAD_IND,LANG_CDE,ID_ISSUER,SAL_IND,RSK_RSN_CDE,TOT_NO_SUBPROD,SCHEME_IND,BOND_IND,6919Spend,PRIM_BUS,SIC_CDE,CUST_CNTCT_TEL_NO,TURNOVER,15314Frequency,15427Frequency,FriSpend,PRI_SEG,HIGH_EDU_LVL,GRAD_TYPE,4820Spend,NO_BANK_SERV,15616Frequency,15318Spend,NO_DDA_ACCT,DEBT_COUNSEL_IND,CNTRY_ESTBLSHMNT,15696Spend,IndustriousSpend,Intentional,6544Frequency,4820Frequency,15466Spend,15303Spend,ACCT_LINK_IND,CUST_REC_OPEN_DATE,ThuSpend,INCOME_AMOUNT,CUST_TYPE,CONSENT_IND,15423Frequency,5541Spend,personalityType,1FrequencyN,IntrovertSpend,MRTL_ASS_REQ_IND,DATE_GRAD,CUST_INC_CDE,prismScore3,brsScore3,CUST_TOT_NO_PROD,SatSpend,DTI_CDE,MRTL_CNTCT_IND,TueFrequency,MonSpend,CUST_JUNK_MAIL_IND,Prepaid_BuySpend,INCOME_AMT_DATE,RES_ZIP_CDE,6919Frequency,EssentialFrequency,15712Frequency,CUST_NO_CHILD,CNTRY_PERM_RES,NON_STD_RATE_IPH,CIF_ID_VERIFIED,Extrovert,CUST_TOT_CR_BAL,15452Frequency,FriFrequency,15318Frequency,JNT_ACC_IND,15313Spend,QUAL_SPECIALITY,CUST_CLS_DATE,CUST_TOT_CR_BALs,CNTRY_CTZNSHP,Prepaid_BuyFrequency,MTD_DR_INT_RCV_AMT,DebitOrdersFrequency,outlier,NO_EMPL_CDE,CUST_NO,IntrovertFrequency,CUST_SEX_CDE,MKT_FNB,CUST_BUS_EST_DATE,CashFrequency,tooManyUncategorised,PROP_OWNR_IND,IndustriousFrequency,RSK_CAT_CDE,CNTRY_REG_HO,CUST_TOT_DR_BALs,CUST_CELL_NO,IntentionalSpend,countBrs,CUST_AUTH_NO,EMPLOYER_NAME,WedFrequency,6544Spend,5411Frequency,PRI_SUB_SEG,15696Frequency,MTD_CR_INT_PD_AMTs,MKT_CELL,MKT_EMAIL,PROOF_OF_DEGREE,FeesFrequency,MRTL_STAT_CDE,NO_ILP_ACCT,15303Frequency,15428Spend,ExtrovertSpend,NO_TDA_ACCT,MKT_FRB_OTH,RACE_CDE,MKT_CR_FRB,DiscretionarySpend,1Frequency,usageCategory,15751Spend,15452Spend,SOCIAL_GRANT_IND,CardPurchasesSpend,15428Frequency,15749Spend,POS_RSK_IND,prismScoreTest,brsScore,CardPurchasesFrequency,CUST_BUS_TEL_NO,INC_EST_ACCURACY,badIndicatorBrs3,15423Spend,6545Spend,SOC_IND,badIndicatorPrism3,_id,INCOME_AMT_TIME,MonFrequency,IntentionalFrequency,5411Spend,NO_WES_ACCT,15751Frequency,15313Frequency,1Spend,15616Spend,badIndicator,DebitOrdersSpend,Industrious,TueSpend,6545Frequency,CUST_DOB,NO_RES_ADDR,EMAIL_ADDR,INCOME_ESTIMATE,CUST_OCPTN_CDE,ThuFrequency,prismScore,FeesSpend,MKT_SMS,CNTRY_NATNLITY,MKT_PHONE,SatFrequency,MTD_CR_INT_PD_AMT,CTO&limit=75000&\n",
      "get /processFileToFrameImport?file_name=prism_data.csv&first_row_column_names=1&separator=comma&\n"
     ]
    }
   ],
   "source": [
    "# ---- Uneditible ----\n",
    "d.export_documents(auth, export_store, \"csv\", db_name, export_store, \"{}\", \"{}\", export_projection, record_count)  \n",
    "hexframename = uf.save_userframe(auth, fs, username)\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Train Model:**\n",
    "___\n",
    "Set training parameters for model and train.\n",
    "- **predict_id:** Id for the prediction (for logging). \n",
    "- **description:** Description of model (for logging).\n",
    "- **model_id:** Id for the model (for logging).\n",
    "- **model_type:** Type of model to build (for logging). \n",
    "- **frame_name:** Name of frame used (for logging).\n",
    "- **frame_name_desc:** Description of frame used (for logging).\n",
    "- **model_purpose:** Purpose of model (for logging).\n",
    "- **version:** Model version (for logging).\n",
    "\n",
    "The following parameters are dependend on what is selected in the algo parameter.\n",
    "\n",
    "- **algo:** Algorithm to use to train model. (Availble algorithms: \"H20-AUTOML\")\n",
    "- **training_frame:** Data frame to use for training the model.\n",
    "- **validation_frame:** Data frame to use for validating the model.\n",
    "- **max_models:** Maximum number of models to build.\n",
    "- **stopping_tolerance:** (TODO)\n",
    "- **max_runtime_secs:** Maximum number of seconds to spend on training.\n",
    "- **stopping_rounds:** (TODO)\n",
    "- **stopping_metric:** (TODO)\n",
    "- **nfolds:** (TODO)\n",
    "- **response_column:** The column or field in the dataset to predict.\n",
    "- **ignored_columns:** List of columns to exclude in the model training.\n",
    "- **hidden:** (TODO)\n",
    "- **exclude_algos:** Algorithms to exclude in the automl run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "version = \"1010\"\n",
    "model_id = fs + version\n",
    "model_purpose = \"Prediction of whether nonbehavioural prism model is correct\"\n",
    "description = \"Automated features store generated for \" + fs\n",
    "model_params = { \n",
    "        \"predict_id\": fs,\n",
    "        \"description\": description,\n",
    "        \"model_id\": model_id,\n",
    "        \"model_type\": \"AUTOML\",\n",
    "        \"frame_name\": hexframename,\n",
    "        \"frame_name_desc\": description,\n",
    "        \"model_purpose\": model_purpose,\n",
    "        \"version\": version,\n",
    "        \"model_parms\": {\n",
    "              \"algo\": \"H2O-AUTOML\",\n",
    "              \"training_frame\": hexframename,\n",
    "              \"validation_frame\": hexframename,\n",
    "              \"max_models\": 10,\n",
    "              \"stopping_tolerance\": 0.005,\n",
    "              \"note_stop\": \"stopping_tolerance of 0.001 for 1m rows and 0.004 for 100k rows\",\n",
    "              \"max_runtime_secs\": 3600,\n",
    "              \"stopping_rounds\": 15,\n",
    "              \"stopping_metric\": \"AUTO\",\n",
    "              \"nfolds\": 4,\n",
    "              \"note_folds\": \"nfolds=0 will disable the stacked ensemble creation process\",\n",
    "              \"response_column\": \"prismResponse\",\n",
    "              \"ignored_columns\": [            \n",
    "                  \"prismResponse\",\n",
    "                  \"other columns in feature store you don't want to be included in the model\"\n",
    "              ],\n",
    "              \"hidden\": [\n",
    "                \"1\"\n",
    "              ],\n",
    "              \"exclude_algos\": [\n",
    "                \"GLM\",\n",
    "                \"StackedEnsemble\",\n",
    "                \"XGBoost\",\n",
    "                \"DeepLearning\",\n",
    "                \"GBM\",\n",
    "                \"Any algorithms that you don't want to be included in the automl run\"\n",
    "              ]\n",
    "            }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get /buildModel?model_id=prism_data1010&model_type=automl&model_parms={\"algo\": \"H2O-AUTOML\", \"training_frame\": \"prism_data.hex\", \"validation_frame\": \"prism_data.hex\", \"max_models\": 10, \"stopping_tolerance\": 0.005, \"note_stop\": \"stopping_tolerance of 0.001 for 1m rows and 0.004 for 100k rows\", \"max_runtime_secs\": 3600, \"stopping_rounds\": 15, \"stopping_metric\": \"AUTO\", \"nfolds\": 4, \"note_folds\": \"nfolds=0 will disable the stacked ensemble creation process\", \"response_column\": \"prismResponse\", \"ignored_columns\": [\"prismResponse\", \"other columns in feature store you don't want to be included in the model\"], \"hidden\": [\"1\"], \"exclude_algos\": [\"GLM\", \"StackedEnsemble\", \"XGBoost\", \"DeepLearning\", \"GBM\", \"Any algorithms that you don't want to be included in the automl run\"]}&\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Uneditible ----\n",
    "hw.train_model(auth, model_id, \"automl\", json.dumps(model_params[\"model_parms\"]))\n",
    "# ---- Uneditible ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "h2o_name = \"GLM_1_AutoML_20210722_145224\"\n",
    "zip_name = h2o_name + \".zip\"\n",
    "hw.download_model_mojo(auth,h2o_name)\n",
    "high_level_mojo = hw.get_train_model(auth, h2o_name, \"user\")\n",
    "model_to_save = high_level_mojo[\"models\"][0]\n",
    "model_to_save[\"model_identity\"] = h2o_name\n",
    "model_to_save[\"userid\"] = \"user\"\n",
    "model_to_save[\"timestamp\"] = \"time_stamp\"\n",
    "pe.save_model(auth,model_to_save)\n",
    "\n",
    "#See some statistics from the saved model\n",
    "pe.get_user_model(auth,h2o_name)\n",
    "stats = hw.get_model_stats(auth,h2o_name,\"ecosystem\",\"variable_importances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "290px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
